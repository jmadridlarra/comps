\documentclass[10pt,twocolumn]{article} 

% required packages for Oxy Comps style
\usepackage{oxycomps} % the main oxycomps style file
\usepackage{times} % use Times as the default font
\usepackage[style=numeric,sorting=nyt]{biblatex} % format the bibliography nicely

\usepackage{amsfonts} % provides many math symbols/fonts
\usepackage{listings} % provides the lstlisting environment
\usepackage{amssymb} % provides many math symbols/fonts
\usepackage{graphicx} % allows insertion of grpahics
\usepackage{hyperref} % creates links within the page and to URLs
\usepackage{url} % formats URLs properly
\usepackage{verbatim} % provides the comment environment
\usepackage{xpatch} % used to patch \textcite

\bibliography{references}
\DeclareNameAlias{default}{last-first}

\xpatchbibmacro{textcite}
  {\printnames{labelname}}
  {\printnames{labelname} (\printfield{year})}
  {}
  {}

\pdfinfo{
    /Title (Clever Name: An Interactive, Generative Art Exhibit)
    /Author (Joaquín Madrid Larrañaga)
}

\title{Clever Name: An Interactive, Generative Art Exhibit}

\author{Joaquín Madrid Larrañaga}
\affiliation{Occidental College}
\email{jmadridlarra@oxy.edu}

\begin{document}

\maketitle

\begin{abstract}
    
\end{abstract}

\section{Introduction}

\section{Problem Context}

From interactive sculptures to light projections, the interactive art scene has enthralled audiences throughout the world \cite{sarto_disneys_2021, noauthor_teamlab_2020}. By allowing audiences to interact with these art pieces, artists have added elements of curiosity, wonder, and suspense. This interaction is usually tactile, verbal, or a motion on the part of the audience that causes a change in the art piece itself.  However, interactive art is not the same as generative art.  Generative art does not necessarily involve interaction on the part of the audience, but instead focuses on generating aspects of the art piece over time.  This type of art is typically associated with art pieces that utilize CGI or other technical aspects that rely on computers or code to generate the art piece \cite{sparacino_narrative_2002}. 
        	
The focus of this paper surrounds an interactive generative art piece that seeks to explore first time interactions.  The COVID-19 pandemic caused lockdowns and isolations across the world and, as a result, the chances of meeting someone new dropped significantly.  Suddenly, there were not any opportunities for people to gather with strangers in order to grow their social circles.  This interactive art installation aims to explore the experience of meeting something for the first time.  As people began leaving isolation after the COVID-19 vaccine was widely available, they were suddenly thrust into various social situations, many of which involved meeting new people.  However, these interactions are often characterized with polite small talk rather than getting to the meat of a conversation.  All personal interactions are characterized by vulnerability from one of the parties, but most first time interactions neglect this step making a conversation feel impersonal or superficial.  During most first time interactions, each member is carefully testing the waters to see if the other party is trustworthy.  Meeting a new animal eliminates this awkward phase of small talk.  Most times animals just want to know if people are a threat, neutral, or an ally.  This categorization is determined through careful sensory inputs such as sniffing, licking, and making noises.  At the same time, people are careful when they meet a new animal in case the animal reacts in an unpredictable way.  For the purposes of this project, interacting with an animal also eliminates the need to connect through language forcing the user to interact with the character through movement and emotion. By generating a fictional character that realistically responds to human interactions, each observer can experience what it is like to gain the trust of a pet for the first time… along with all the unpredictability that comes with interacting with animals. 


\section{Technical Background}

At the highest level, this installation focuses on human movement as the primary way of interacting with a computer.  This movement will be captured by a camera that transmits a live video feed into the computer.  By using JMyron \cite{noauthor_myron_nodate}, a video capture and computer vision software, the computer will be able to recognize different actions performed by the user. Then, these actions will be categorized and used to inform an algorithm to determine what the CGI character does.  This character will be created using OpenGL, a python based CGI software \cite{andreussi_realtimerendering_nodate}.  Specifically, a character will be designed and rigged using OpenGL, but it’s behavior (and therefore movement) will be dictated by a Markov chain.  Markov chains offer a powerful directed stochastic form of artificial intelligence where the computer is given a predetermined tree of possible actions based upon the previous action.  Then, according to some trained or predetermined probabiity, the computer will choose a path down the Markov chain. This Markov chain will take the user’s behavior into consideration and then determine the next logical response according to some probability.  There is a possibility that this probability can be determined by training the Markov chain, but these probabilities will likely be randomized. 
By categorizing the user’s movements into a type of emotion or intention, the Markov chain can determine an appropriate response, rather than trying to respond to the infinite number of possible movements by the user on a case by case basis. Similarly, the Markov chain limits the amount of possible reactions by the CGI character, thereby limiting the amount of animation that needs to be prepared. 


\section{Prior Work}

\citetitle{kwon_real-time_nodate} by \citeauthor{kwon_real-time_nodate} highlights many interactive generative art exhibits from the early 2000s. In 2003, Scott Snibbe created a visualization that recorded users' shadows and played them back allowing the user to add new shadows to the loop - similar to a guitar feedback loop.  Then, in 2015, Philip Worthington created the installation ``Shadow Monsters`` which used machine learning to recognize specific shapes and features in a user's shadow and modify it \cite{houston_public_media_mfah_2015}.  For example, shadows that look like circles will be made into eyes, and shadows that look like intersecting lines will be made into mouths.  This transformation happens in real time and artificial extremeties are added in real time to the shadow. These two installations forcus on modifying shadows from the user. However, ``Future You`` (2019) from Universal Everything, a technological art company, focuses on using the user as a puppeteer of sorts to animate a unique CGI character \cite{noauthor_future_2019}. This CGI character is a humanoid, futuristic being that is unique for each user based upon predetermined variables. Additionally, this character undergoes an evolution every 5 seconds becoming more complex the longer a user interacts with it.  In this way, the program is generating and modifying the art based upon the user's actions according to various variables (time and appearance).  This paper describes an art installation that uses various aspects from all of this previous work. 

\subsection{Goals}

\subsection{Audience}

\subsection{Requirements}

\section{Sections of the Oxy CS Comps Paper}

\subsection{Introduction and Background}

\subsection{Prior Work}

\subsection{Methods}

\subsection{Evaluation}

\subsection{Ethical Considerations}

\subsection{Limitations, Future Work, and Conclusion}

\subsection{Appendices}

\section{Conclusion}

\printbibliography 

\end{document}
